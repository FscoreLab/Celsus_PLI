#!/usr/bin/env python3
"""
FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è CT-CLIP + LightGBM –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
"""

import asyncio
import gc
import logging
import os
import shutil
import sys
import tempfile
import time
from datetime import datetime
from pathlib import Path
from typing import Optional

import torch
from fastapi import FastAPI, File, HTTPException, UploadFile, Request
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from starlette.middleware.base import BaseHTTPMiddleware

sys.path.append(str(Path(__file__).parent.parent))

from api.inference_service import LightGBMInferenceService

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class CUDACleanupMiddleware(BaseHTTPMiddleware):
    """Middleware –¥–ª—è –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ CUDA –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."""
    
    async def dispatch(self, request: Request, call_next):
        try:
            response = await call_next(request)
            return response
        finally:
            try:
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                gc.collect()
                logger.debug("üßπ CUDA –ø–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞ –ø–æ—Å–ª–µ –∑–∞–ø—Ä–æ—Å–∞")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ CUDA –ø–∞–º—è—Ç–∏: {e}")


app = FastAPI(
    title="CT-CLIP + LightGBM Inference API",
    description="API –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ CT-CLIP –º–æ–¥–µ–ª–µ–π —Å LightGBM –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –Ω–∞ DICOM –∞—Ä—Ö–∏–≤–∞—Ö",
    version="2.0.0",
)

# –î–æ–±–∞–≤–ª—è–µ–º middleware –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ CUDA –ø–∞–º—è—Ç–∏
app.add_middleware(CUDACleanupMiddleware)

SUPERVISED_MODEL_PATH = os.getenv("SUPERVISED_MODEL_PATH", "/app/models/supervised_model.pt")
CTCLIP_MODEL_PATH = os.getenv("CTCLIP_MODEL_PATH", "/app/models/CT_VocabFine_v2.pt")
LIGHTGBM_MODEL_PATH = os.getenv("LIGHTGBM_MODEL_PATH", "/app/models/lightgbm_model.pkl")
OPTIMAL_THRESHOLD = float(os.getenv("OPTIMAL_THRESHOLD", "0.5"))
DEVICE = os.getenv("DEVICE", "cuda")

DIFFUSION_CLASSIFIER_PATH = os.getenv("DIFFUSION_CLASSIFIER_PATH", None)
DIFFUSION_UNET_PATH = os.getenv("DIFFUSION_UNET_PATH", None)
CLASSIFIER_SCALE = float(os.getenv("CLASSIFIER_SCALE", "100.0"))

# –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º FVLM
FVLM_MODEL_PATH = os.getenv("FVLM_MODEL_PATH", "/app/models/fvlm/fvlm_model.pth")
FVLM_MAE_WEIGHTS_PATH = os.getenv("FVLM_MAE_WEIGHTS_PATH", "/app/models/fvlm/mae_pretrain_vit_base.pth")
FVLM_BERT_PATH = os.getenv("FVLM_BERT_PATH", "/app/models/fvlm/BiomedVLP-CXR-BERT-specialized")
FVLM_CONFIG_PATH = os.getenv("FVLM_CONFIG_PATH", None)

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è DICOM –∞—Ä—Ö–∏–≤–æ–≤
DICOM_ARCHIVE_DIR = os.getenv("DICOM_ARCHIVE_DIR", None)
SAVE_DICOM_ARCHIVES = DICOM_ARCHIVE_DIR is not None

inference_service = None
processing_lock = asyncio.Lock()


class InferenceResponse(BaseModel):
    """–ú–æ–¥–µ–ª—å –æ—Ç–≤–µ—Ç–∞ API."""

    study_uid: str
    series_uid: str
    probability_of_pathology: float
    pathology: int  # 0 (–Ω–æ—Ä–º–∞) –∏–ª–∏ 1 (–ø–∞—Ç–æ–ª–æ–≥–∏—è)
    top_pathologies: list[str]  # –¢–æ–ø-–ø–∞—Ç–æ–ª–æ–≥–∏–∏ –æ—Ç 3 –º–æ–¥–µ–ª–µ–π: MedNeXt, FVLM, CT-CLIP
    processing_status: str
    time_of_processing: float


@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ."""
    global inference_service

    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CT-CLIP + Diffusion + LightGBM Inference Service...")
    logger.info(f"Supervised Model: {SUPERVISED_MODEL_PATH}")
    logger.info(f"CT-CLIP Model: {CTCLIP_MODEL_PATH}")
    logger.info(f"LightGBM Model: {LIGHTGBM_MODEL_PATH}")
    logger.info(f"Optimal Threshold: {OPTIMAL_THRESHOLD}")
    logger.info(f"Device: {DEVICE}")
    
    if SAVE_DICOM_ARCHIVES:
        logger.info(f"DICOM Archive Directory: {DICOM_ARCHIVE_DIR}")
    else:
        logger.info("DICOM Archive Directory: Not configured (archives will not be saved)")

    if DIFFUSION_CLASSIFIER_PATH:
        logger.info(f"Diffusion Classifier: {DIFFUSION_CLASSIFIER_PATH}")
    if DIFFUSION_UNET_PATH:
        logger.info(f"Diffusion UNet: {DIFFUSION_UNET_PATH}")
        logger.info(f"Classifier Scale: {CLASSIFIER_SCALE}")

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è DICOM –∞—Ä—Ö–∏–≤–æ–≤ (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ)
    if SAVE_DICOM_ARCHIVES:
        os.makedirs(DICOM_ARCHIVE_DIR, exist_ok=True)
        logger.info(f"‚úÖ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∞—Ä—Ö–∏–≤–æ–≤ —Å–æ–∑–¥–∞–Ω–∞: {DICOM_ARCHIVE_DIR}")

    if not os.path.exists(SUPERVISED_MODEL_PATH):
        raise FileNotFoundError(f"Supervised –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {SUPERVISED_MODEL_PATH}")
    if not os.path.exists(CTCLIP_MODEL_PATH):
        raise FileNotFoundError(f"CT-CLIP –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {CTCLIP_MODEL_PATH}")
    if not os.path.exists(LIGHTGBM_MODEL_PATH):
        raise FileNotFoundError(f"LightGBM –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {LIGHTGBM_MODEL_PATH}")

    if DIFFUSION_CLASSIFIER_PATH and not os.path.exists(DIFFUSION_CLASSIFIER_PATH):
        raise FileNotFoundError(f"Diffusion classifier –Ω–µ –Ω–∞–π–¥–µ–Ω: {DIFFUSION_CLASSIFIER_PATH}")
    if DIFFUSION_UNET_PATH and not os.path.exists(DIFFUSION_UNET_PATH):
        raise FileNotFoundError(f"Diffusion UNet –Ω–µ –Ω–∞–π–¥–µ–Ω: {DIFFUSION_UNET_PATH}")

    inference_service = LightGBMInferenceService(
        supervised_model_path=SUPERVISED_MODEL_PATH,
        ctclip_model_path=CTCLIP_MODEL_PATH,
        lightgbm_model_path=LIGHTGBM_MODEL_PATH,
        optimal_threshold=OPTIMAL_THRESHOLD,
        device=DEVICE,
        diffusion_classifier_path=DIFFUSION_CLASSIFIER_PATH,
        diffusion_unet_path=DIFFUSION_UNET_PATH,
        classifier_scale=CLASSIFIER_SCALE,
        # FVLM –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        fvlm_model_path=FVLM_MODEL_PATH if os.path.exists(FVLM_MODEL_PATH) else None,
        fvlm_mae_weights_path=FVLM_MAE_WEIGHTS_PATH if os.path.exists(FVLM_MAE_WEIGHTS_PATH) else None,
        fvlm_bert_path=FVLM_BERT_PATH if os.path.exists(FVLM_BERT_PATH) else None,
        fvlm_config_path=FVLM_CONFIG_PATH,
    )

    logger.info("‚úÖ –°–µ—Ä–≤–∏—Å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ!")


@app.get("/")
async def root():
    """Health check endpoint."""
    return {
        "status": "running",
        "service": "CT-CLIP + LightGBM Inference API",
        "version": "2.0.0",
    }


@app.get("/health")
async def health():
    """Health check endpoint."""
    return {"status": "healthy"}


def save_dicom_archive(temp_file_path: str, study_uid: str, original_filename: str) -> Optional[str]:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç DICOM –∞—Ä—Ö–∏–≤ –≤ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.

    Args:
        temp_file_path: –ü—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        study_uid: Study UID –∏–∑ DICOM
        original_filename: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞

    Returns:
        –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É –∞—Ä—Ö–∏–≤—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not SAVE_DICOM_ARCHIVES:
        logger.debug("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ DICOM –∞—Ä—Ö–∏–≤–æ–≤ –æ—Ç–∫–ª—é—á–µ–Ω–æ")
        return None
        
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        archive_filename = f"{timestamp}_{study_uid}.zip"
        archive_path = os.path.join(DICOM_ARCHIVE_DIR, archive_filename)

        shutil.copy2(temp_file_path, archive_path)
        logger.info(f"‚úÖ –ê—Ä—Ö–∏–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {archive_filename}")
        return archive_path
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—Ä—Ö–∏–≤–∞: {e}")
        return None


@app.post("/predict", response_model=InferenceResponse)
async def predict(file: UploadFile = File(...)):
    """
    –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ DICOM –∞—Ä—Ö–∏–≤–µ.

    Args:
        file: ZIP –∞—Ä—Ö–∏–≤ —Å DICOM —Ñ–∞–π–ª–∞–º–∏

    Returns:
        InferenceResponse —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    """
    if inference_service is None:
        raise HTTPException(status_code=503, detail="–°–µ—Ä–≤–∏—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    if not file.filename.endswith(".zip"):
        raise HTTPException(status_code=400, detail="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ ZIP –∞—Ä—Ö–∏–≤—ã —Å DICOM —Ñ–∞–π–ª–∞–º–∏")

    async with processing_lock:
        start_time = time.time()

        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".zip") as temp_file:
                content = await file.read()
                temp_file.write(content)
                temp_file_path = temp_file.name

            logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: {file.filename} ({len(content)} bytes)")

            result = inference_service.process_zip_archive(temp_file_path)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—Ä—Ö–∏–≤ –≤ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            save_dicom_archive(temp_file_path, result["study_uid"], file.filename)

            os.unlink(temp_file_path)

            processing_time = time.time() - start_time
            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f} —Å–µ–∫")

            # –î–ª—è –Ω–æ—Ä–º—ã –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø–∞—Ç–æ–ª–æ–≥–∏–π
            top_pathologies = result.get("top_pathologies", []) if result["pathology"] == 1 else []

            return InferenceResponse(
                study_uid=result["study_uid"],
                series_uid=result["series_uid"],
                probability_of_pathology=result["probability_of_pathology"],
                pathology=result["pathology"],
                top_pathologies=top_pathologies,
                processing_status="Success",
                time_of_processing=processing_time,
            )

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file.filename}: {e}", exc_info=True)
            processing_time = time.time() - start_time

            try:
                if "temp_file_path" in locals():
                    os.unlink(temp_file_path)
            except Exception:
                pass

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏
            error_message = str(e)
            status_code = 500

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∏—Å–∫–ª—é—á–µ–Ω–∏—è –Ω–∞–ø—Ä—è–º—É—é
            exception_class_name = e.__class__.__name__

            if (
                exception_class_name == "LungsNotFoundError"
                or "Lungs not found" in error_message
                or "too low relative percentage" in error_message
            ):
                status_code = 422  # Unprocessable Entity
                error_message = "–õ–µ–≥–∫–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏–ª–∏ –∏—Ö " "–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –º–∞–ª."
                logger.warning(f"‚ö†Ô∏è –õ–µ–≥–∫–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {file.filename}")
            elif exception_class_name == "InvalidLungsLengthError" or (
                "too small" in error_message and "mm" in error_message
            ):
                status_code = 422  # Unprocessable Entity
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
                if hasattr(e, "detail") and isinstance(e.detail, dict):
                    error_message = e.detail.get("message", str(e))
                else:
                    error_message = f"–î–ª–∏–Ω–∞ –ª–µ–≥–∫–∏—Ö —Å–ª–∏—à–∫–æ–º –º–∞–ª–∞. {error_message}"
                logger.warning(f"‚ö†Ô∏è –ö–æ—Ä–æ—Ç–∫–∏–µ –ª–µ–≥–∫–∏–µ: {file.filename}")
            elif "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–µ—Ä–∏–π —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ä–µ–∑–æ–≤" in error_message:
                status_code = 422  # Unprocessable Entity
                error_message = "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ä–µ–∑–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 20 –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ä–µ–∑–æ–≤)."
                logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ä–µ–∑–æ–≤: {file.filename}")

            return JSONResponse(
                status_code=status_code,
                content={
                    "study_uid": "",
                    "series_uid": "",
                    "probability_of_pathology": None,
                    "pathology": None,
                    "most_dangerous_pathology_type": None,
                    "processing_status": "Failure",
                    "time_of_processing": processing_time,
                    "error": error_message,
                },
            )


@app.post("/predict_nifti", response_model=InferenceResponse)
async def predict_nifti(file: UploadFile = File(...)):
    """
    –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ NIFTI —Ñ–∞–π–ª–µ –Ω–∞–ø—Ä—è–º—É—é.

    Args:
        file: NIFTI —Ñ–∞–π–ª (.nii.gz)

    Returns:
        InferenceResponse —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    """
    if inference_service is None:
        raise HTTPException(status_code=503, detail="–°–µ—Ä–≤–∏—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    if not file.filename.endswith(".nii.gz") and not file.filename.endswith(".nii"):
        raise HTTPException(status_code=400, detail="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ NIFTI —Ñ–∞–π–ª—ã (.nii.gz –∏–ª–∏ .nii)")

    async with processing_lock:
        start_time = time.time()

        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º NIFTI —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            with tempfile.NamedTemporaryFile(delete=False, suffix=".nii.gz") as temp_file:
                content = await file.read()
                temp_file.write(content)
                temp_file_path = temp_file.name

            logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NIFTI —Ñ–∞–π–ª: {file.filename} ({len(content)} bytes)")

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º dummy study_uid –∏ series_uid –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            volume_name = file.filename.replace(".nii.gz", "").replace(".nii", "")
            study_uid = f"nifti_{volume_name}"
            series_uid = f"nifti_{volume_name}_series"

            # –í—ã–∑—ã–≤–∞–µ–º process_nifti_file –Ω–∞–ø—Ä—è–º—É—é
            result = inference_service.process_nifti_file(temp_file_path, study_uid, series_uid)

            os.unlink(temp_file_path)

            processing_time = time.time() - start_time
            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f} —Å–µ–∫")

            # –î–ª—è –Ω–æ—Ä–º—ã –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø–∞—Ç–æ–ª–æ–≥–∏–π
            top_pathologies = result.get("top_pathologies", []) if result["pathology"] == 1 else []

            return InferenceResponse(
                study_uid=result["study_uid"],
                series_uid=result["series_uid"],
                probability_of_pathology=result["probability_of_pathology"],
                pathology=result["pathology"],
                top_pathologies=top_pathologies,
                processing_status="Success",
                time_of_processing=processing_time,
            )

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file.filename}: {e}", exc_info=True)
            processing_time = time.time() - start_time

            try:
                if "temp_file_path" in locals():
                    os.unlink(temp_file_path)
            except Exception:
                pass

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –æ—à–∏–±–æ–∫
            error_message = str(e)
            status_code = 500

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∏—Å–∫–ª—é—á–µ–Ω–∏—è –Ω–∞–ø—Ä—è–º—É—é
            exception_class_name = e.__class__.__name__

            if (
                exception_class_name == "LungsNotFoundError"
                or "Lungs not found" in error_message
                or "too low relative percentage" in error_message
            ):
                status_code = 422
                error_message = "–õ–µ–≥–∫–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏–ª–∏ –∏—Ö " "–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –º–∞–ª."
                logger.warning(f"‚ö†Ô∏è –õ–µ–≥–∫–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {file.filename}")
            elif exception_class_name == "InvalidLungsLengthError" or (
                "too small" in error_message and "mm" in error_message
            ):
                status_code = 422
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
                if hasattr(e, "detail") and isinstance(e.detail, dict):
                    error_message = e.detail.get("message", str(e))
                else:
                    error_message = f"–î–ª–∏–Ω–∞ –ª–µ–≥–∫–∏—Ö —Å–ª–∏—à–∫–æ–º –º–∞–ª–∞. {error_message}"
                logger.warning(f"‚ö†Ô∏è –ö–æ—Ä–æ—Ç–∫–∏–µ –ª–µ–≥–∫–∏–µ: {file.filename}")

            return JSONResponse(
                status_code=status_code,
                content={
                    "study_uid": "",
                    "series_uid": "",
                    "probability_of_pathology": None,
                    "pathology": None,
                    "top_pathologies": [],
                    "processing_status": "Failure",
                    "time_of_processing": processing_time,
                    "error": error_message,
                },
            )


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
    )
