#!/usr/bin/env python3
"""
Batch Inference Client –¥–ª—è CT-CLIP + LightGBM API

–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–∞–ø–∫—É —Å ZIP –∞—Ä—Ö–∏–≤–∞–º–∏ DICOM —Ñ–∞–π–ª–æ–≤ –∏ —Å–æ–∑–¥–∞–µ—Ç Excel –æ—Ç—á–µ—Ç.
"""

import argparse
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import List

import pandas as pd
import requests
from tqdm import tqdm


def find_zip_archives(input_dir: Path) -> List[Path]:
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ ZIP –∞—Ä—Ö–∏–≤—ã –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
    zip_files = list(input_dir.glob("*.zip"))
    return sorted(zip_files)


def process_single_archive(api_url: str, archive_path: Path) -> dict:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ–¥–∏–Ω –∞—Ä—Ö–∏–≤ –≤ API –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    try:
        start_time = time.time()

        with open(archive_path, "rb") as f:
            files = {"file": (archive_path.name, f, "application/zip")}
            response = requests.post(f"{api_url}/predict", files=files, timeout=600)  # 10 –º–∏–Ω—É—Ç

        processing_time = time.time() - start_time

        if response.status_code == 200:
            result = response.json()
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º top_pathologies –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è most_dangerous_pathology_type
            if "top_pathologies" in result:
                result["most_dangerous_pathology_type"] = (
                    ", ".join(result["top_pathologies"]) if result["top_pathologies"] else ""
                )
            else:
                result["most_dangerous_pathology_type"] = ""
            result["path_to_study"] = str(archive_path.absolute())
            result["processing_time_total"] = processing_time
            return result
        else:
            error_data = response.json() if response.headers.get("content-type") == "application/json" else {}
            return {
                "path_to_study": str(archive_path.absolute()),
                "study_uid": "",
                "series_uid": "",
                "probability_of_pathology": 0.0,
                "pathology": "Unknown",
                "most_dangerous_pathology_type": "Unknown",
                "processing_status": "Failure",
                "time_of_processing": processing_time,
                "error": error_data.get("error", f"HTTP {response.status_code}"),
            }

    except requests.exceptions.Timeout:
        return {
            "path_to_study": str(archive_path.absolute()),
            "study_uid": "",
            "series_uid": "",
            "probability_of_pathology": 0.0,
            "pathology": "Unknown",
            "most_dangerous_pathology_type": "Unknown",
            "processing_status": "Failure",
            "time_of_processing": 0.0,
            "error": "Request timeout (> 10 minutes)",
        }
    except Exception as e:
        return {
            "path_to_study": str(archive_path.absolute()),
            "study_uid": "",
            "series_uid": "",
            "probability_of_pathology": 0.0,
            "pathology": "Unknown",
            "most_dangerous_pathology_type": "Unknown",
            "processing_status": "Failure",
            "time_of_processing": 0.0,
            "error": str(e),
        }


def batch_process(api_url: str, input_dir: Path, output_excel: Path):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∞—Ä—Ö–∏–≤—ã –≤ –ø–∞–ø–∫–µ –∏ —Å–æ–∑–¥–∞–µ—Ç Excel –æ—Ç—á–µ—Ç."""
    print("=" * 80)
    print("CT-CLIP + LightGBM Batch Inference Client")
    print("=" * 80)

    print(f"\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API: {api_url}")
    try:
        response = requests.get(f"{api_url}/health", timeout=10)
        if response.status_code == 200:
            print("‚úÖ API –¥–æ—Å—Ç—É–ø–µ–Ω")
        else:
            print(f"‚ùå API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (HTTP {response.status_code})")
            return
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API: {e}")
        return

    print(f"\nüìÇ –ü–æ–∏—Å–∫ ZIP –∞—Ä—Ö–∏–≤–æ–≤ –≤: {input_dir}")
    archives = find_zip_archives(input_dir)
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(archives)} –∞—Ä—Ö–∏–≤–æ–≤")

    if not archives:
        print("‚ùå –ê—Ä—Ö–∏–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return

    results = []
    print("\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...")

    for archive_path in tqdm(archives, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤"):
        result = process_single_archive(api_url, archive_path)
        results.append(result)

        status_emoji = "‚úÖ" if result["processing_status"] == "Success" else "‚ùå"
        tqdm.write(
            f"{status_emoji} {archive_path.name}: {result['pathology']} "
            f"(P={result['probability_of_pathology']:.3f}, "
            f"{result['time_of_processing']:.1f}s)"
        )

    df_results = pd.DataFrame(results)

    # –ë–∞–∑–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤—Å–µ–≥–¥–∞
    base_columns = [
        "path_to_study",
        "study_uid",
        "series_uid",
        "probability_of_pathology",
        "pathology",
        "processing_status",
        "time_of_processing",
    ]

    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    optional_columns = [
        "most_dangerous_pathology_type",
        "error",
    ]

    # –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
    final_columns = [col for col in base_columns if col in df_results.columns]
    for col in optional_columns:
        if col in df_results.columns:
            final_columns.append(col)

    df_final = df_results[final_columns].copy()

    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤: {output_excel}")
    df_final.to_excel(output_excel, index=False, engine="openpyxl")

    print("\n" + "=" * 80)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò")
    print("=" * 80)

    total = len(results)
    success = sum(1 for r in results if r["processing_status"] == "Success")
    failure = total - success

    print(f"–í—Å–µ–≥–æ –∞—Ä—Ö–∏–≤–æ–≤: {total}")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {success} ({success/total*100:.1f}%)")
    print(f"‚ùå –û—à–∏–±–∫–∏: {failure} ({failure/total*100:.1f}%)")

    if success > 0:
        success_results = [r for r in results if r["processing_status"] == "Success"]
        pathology_counts = pd.Series([r["pathology"] for r in success_results]).value_counts()

        print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–≥–Ω–æ–∑–∞–º (—É—Å–ø–µ—à–Ω—ã–µ):")
        for pathology, count in pathology_counts.items():
            print(f"  {pathology}: {count} ({count/success*100:.1f}%)")

        times = [r["time_of_processing"] for r in success_results]
        print("\n–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—É—Å–ø–µ—à–Ω—ã–µ):")
        print(f"  –°—Ä–µ–¥–Ω–µ–µ: {sum(times)/len(times):.1f} —Å–µ–∫")
        print(f"  –ú–∏–Ω: {min(times):.1f} —Å–µ–∫")
        print(f"  –ú–∞–∫—Å: {max(times):.1f} —Å–µ–∫")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞—Ç–æ–ª–æ–≥–∏—è–º (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö)
        if success_results and "most_dangerous_pathology_type" in success_results[0]:
            dangerous_pathologies = pd.Series(
                [r["most_dangerous_pathology_type"] for r in success_results]
            ).value_counts()
            print("\n–¢–æ–ø-5 –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –ø–∞—Ç–æ–ª–æ–≥–∏–π:")
            for i, (pathology, count) in enumerate(dangerous_pathologies.head(5).items(), 1):
                print(f"  {i}. {pathology}: {count}")

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_excel}")


def main():
    parser = argparse.ArgumentParser(description="Batch Inference Client –¥–ª—è CT-CLIP + LightGBM API")
    parser.add_argument(
        "--input-dir",
        type=str,
        required=True,
        help="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å ZIP –∞—Ä—Ö–∏–≤–∞–º–∏ DICOM —Ñ–∞–π–ª–æ–≤",
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è Excel —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: results_YYYYMMDD_HHMMSS.xlsx)",
    )
    parser.add_argument(
        "--api-url",
        type=str,
        default="http://localhost:8000",
        help="URL API —Å–µ—Ä–≤–∏—Å–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: http://localhost:8000)",
    )

    args = parser.parse_args()

    input_dir = Path(args.input_dir)
    if not input_dir.exists():
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {input_dir}")
        return 1

    if args.output:
        output_excel = Path(args.output)
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_excel = Path(f"results_{timestamp}.xlsx")

    batch_process(args.api_url, input_dir, output_excel)
    return 0


if __name__ == "__main__":
    sys.exit(main())
